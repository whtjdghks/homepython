{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e48f4a9",
   "metadata": {},
   "source": [
    "# 선형 회귀\n",
    "### 독립변수가 종속변수에 영향을 미치는지 알아보고자 할 때 실시하는 분석 방법\n",
    "\n",
    "#### 선형성\n",
    "선형성이라는 기본 가정이 충족된 상태에서 독립변수와 종속변수의 관계를 설명하거나 예측하는 통계방법으로 회귀분석에서 독립변수에 따라 종속 변수의 값이 일정한 패턴으로 변해가는데 , 이러한 변수간의 관계를 나타내느 회귀선이 직선에 가깝게 나타나는 경우를 의미한다.<br>\n",
    "- 선형이기 때문에 어떤 X값이라도 W와b만 정의 되면 알 수있다.\n",
    "\n",
    "#### 종류\n",
    "- 단순회귀분석 : 독립변수가 하나인 경우\n",
    "- 다중회귀분석 : 독립변수가 여러 개인 경우\n",
    "\n",
    "#### 단순선형회귀 분석\n",
    "H(x) = Wx+b<br>\n",
    "x: 독립변수<br>\n",
    "y: 종속변수<br>\n",
    "W:직선의 기울기(가중치:weight)<br>\n",
    "b:y절편(bias)\n",
    "\n",
    "#### 편차\n",
    "- 수학 및 통계학에서 편차는 자료값 또는 변량과 평균의 차이를 나타내는 수치\n",
    "- 편차를 살펴보면 자료들이 평균을 중심으로 얼마나 퍼져 있는지를 알 수 있다.\n",
    "- 자료값이 평균보다 크면 편차는 양의 값을 , 평균보다 작으면 음의 값을 가지게 된다.\n",
    "- 편차의 크기는 차이의 크기를 나타낸다.\n",
    "- 편차의 절댓값은 절대편차,편차의 제곱은 제곱편차\n",
    "\n",
    "## 용어정의\n",
    "### 잔차 \n",
    "- 회귀분석에서 종속변수와 적합값 예상값의 차이,잔차는 종속변수 적합값으로 정의 \n",
    "### 분산 \n",
    "- 편차의 제곱 \n",
    "### 표준 편차 \n",
    "- 분산의 제곱근\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9efdf66",
   "metadata": {},
   "source": [
    "# 1.단순회귀분석\n",
    "- 1) 가설함수정의  y=wx+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414b3481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow를 이용한 Linear Regression(선형회귀)\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.random.set_seed(777) # 항상 같은 결과를 나오게 하기위해 random의 seed값을 고정\n",
    "\n",
    "# X and X data - 데이터를 학습시켜 피드백을 받도록 한다.\n",
    "x_train =[1,2,3] # 입력 데이터\n",
    "y_train =[1,2,3] # 결과 데이터\n",
    "\n",
    "# 1) 가설함수 정의 : y =wx+b\n",
    "W = tf.Variable(tf.random.normal([1]),name ='weight') \n",
    "# tf.Variable - 변수로 만들어 함수, 이 변수는 학습이 되어질 때마다 변경되어 질 수 있게 한다.\n",
    "# tf.random.normal - 랜덤 값으로 초기값 생성\n",
    "\n",
    "b = tf.Variable(tf.random.normal([1]),name ='bias')\n",
    "\n",
    "hypothesis = x_train *W+b # 스칼라 함수 일 때 W와 x값은 교환법칙이 가능하다 - 예측값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccacea4",
   "metadata": {},
   "source": [
    "# 손실 함수 정의\n",
    "- 선형회귀  일 때, 평균 제곱 오차 사용 <br>\n",
    "실제 값과 예측 값의 차이를 제곱하여 평균을 낸 값이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8cb2f260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) 손실 함수 정의\n",
    "loss = tf.reduce_mean(tf.square(hypothesis - y_train))\n",
    "# tf.square : 제곱 , tf.reduce_Mean : 평균\n",
    "# 실제값 과 예측 값의 차이에서 제곱을 한 값에 평균 값"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1986eb",
   "metadata": {},
   "source": [
    "# 경사하강법 \n",
    "- 손실이 계산 될 때마다 경사하강법을 넣어서 최적의 w,b값을 찾도록 학습시킴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b32b91b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
