{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3dbd45e",
   "metadata": {},
   "source": [
    "# Estimator\n",
    "\n",
    "학습 : fit()\n",
    "예측 : predict()\n",
    "\n",
    "### 분류구현 클래스\n",
    "DecisionTreeClassifier<br>\n",
    "RandomForestClassifier<br>\n",
    "GradientBoostingClassifer<br>\n",
    "GaussianNB<br>\n",
    "SVC<br>\n",
    "\n",
    "### 회귀 구현 클래스\n",
    "LinearRegression<br>\n",
    "Ridge<br>\n",
    "Lasso<br>\n",
    "RandomForestRegressor<br>\n",
    "GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51891a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b26b2f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4b7c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "83419ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_data = iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b35dae6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris target 값 : [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "iris target 명 : ['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "iris_label = iris.target\n",
    "print('iris target 값 :',iris_label)\n",
    "print('iris target 명 :',iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97392b52",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = pd.DataFrame(data = iris_data , columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccc1f8",
   "metadata": {},
   "source": [
    "# 데이터 셋트 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27a66522",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(iris_data,iris_label,\n",
    "                                               test_size = 0.2 , random_state = 11) # 0.2 전체중 테스트 20% 학습 80% 분할"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9deced72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DecisionTreeClassifier 객체 생성\n",
    "dt_clf = DecisionTreeClassifier(random_state = 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7ab944",
   "metadata": {},
   "source": [
    "# 모델학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc518ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(random_state=11)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 수행\n",
    "dt_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddffb6a",
   "metadata": {},
   "source": [
    "# 예측수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5612183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 DecisionTreeClassifier 객체에서 테스트 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ceb0a",
   "metadata": {},
   "source": [
    "# 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db48bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"예측 정확도 : {0:.4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a5f498",
   "metadata": {},
   "source": [
    "1. 데이터 세트 분리 : 데이터를 학습데이터와 테스트 데이터로 분리\n",
    "2. 모델 학습 : 학습 데이터를 기반으로 ML 알고리즘을 적용해 모델을 학습 시킨다\n",
    "3. 예측 수행 : 학습된 ML 모델을 이용해서 테스트 데이터의 분류( 즉 ,  붓꽃 종류) 를 예측\n",
    "4. 평가 : 이렇게 예측된 결괏값과 테스트 데이터의 실제 결괏값을 비교해 ML 모델 성능을 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a2f46c",
   "metadata": {},
   "source": [
    "# 분류 (Classifier) + 회귀 (Regressor) = Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b62c23",
   "metadata": {},
   "source": [
    "### 분류나 회귀 연습용 데이터\n",
    "datasets.load_boston() = 회귀용도 , 미국 보스턴의 집 피처들과 가격에 대한 데이터 세트 <br>\n",
    "datasets.load_breast_cancer() = 분류용도 , 위스콘신 유방암 피처들과 악성/음성 레이블 데이터 세트<br>\n",
    "datasets.load_diabetes() = 회귀용도 , 당뇨데이터세트<br>\n",
    "datasets.load_digits() = 분류용도 , 0에서 9까지 숫자의 이미 픽셀 데이터 세트<br>\n",
    "datasets.load_iris() = 분류용도  , 붓꽃에 대한 피처를 가진 데이터 세트<br>\n",
    "\n",
    "### 추후\n",
    "fetch 계열 데이터 크기가 커서 따로 내려받아야함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681346a3",
   "metadata": {},
   "source": [
    "### 분류와 클러스터링을 위한 표본 데이터 생성기\n",
    "#### datasets.make_classifications()<br>\n",
    "분류를 위한 데이터 세트를 만든다. 특히 높은 상관도 , 불필요한 속성등의 노이즈 효과를 위한 데이터를 무작위로 생성해준다.<br>\n",
    "#### datasets.make_blobs()<br>\n",
    "클러스터링을 위한 데이터세트를 무작위로 생성 , 군집 지정개수에 따라 여러가지 클러스터링을 위한 데이터 세트를 쉽게 만들어준다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35334917",
   "metadata": {},
   "source": [
    "data는 피처의 데이터 세트를 가리킨다<br>\n",
    "target은 분류시 레이블 값 회귀일때 숫자 결괏값 데이터 세트<br>\n",
    "target_names는 개별 레이블의 이름을 나타낸다<br>\n",
    "feature_names는 피처의 이름<br>\n",
    "DESCR은 데이터세트에 대한 설명과 각 피처의 설명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37827108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.utils.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃데이터 세트 생성\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_data = load_iris()\n",
    "print(type(iris_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3195c7f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이 세트의 키들: dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename'])\n"
     ]
    }
   ],
   "source": [
    "keys = iris_data.keys()\n",
    "print(\"붓꽃 데이 세트의 키들:\",keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b2a98f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " feature_names의 type: <class 'list'>\n",
      " feature_names의 shape: 4\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "\n",
      " target_names의 tpye: <class 'numpy.ndarray'>\n",
      "target_names의 shape: 3\n",
      "['setosa' 'versicolor' 'virginica']\n",
      "\n",
      " data의 type은 :  <class 'numpy.ndarray'>\n",
      "data의 shape :  150\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.4 2.9 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.1]\n",
      " [5.4 3.7 1.5 0.2]\n",
      " [4.8 3.4 1.6 0.2]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [4.3 3.  1.1 0.1]\n",
      " [5.8 4.  1.2 0.2]\n",
      " [5.7 4.4 1.5 0.4]\n",
      " [5.4 3.9 1.3 0.4]\n",
      " [5.1 3.5 1.4 0.3]\n",
      " [5.7 3.8 1.7 0.3]\n",
      " [5.1 3.8 1.5 0.3]\n",
      " [5.4 3.4 1.7 0.2]\n",
      " [5.1 3.7 1.5 0.4]\n",
      " [4.6 3.6 1.  0.2]\n",
      " [5.1 3.3 1.7 0.5]\n",
      " [4.8 3.4 1.9 0.2]\n",
      " [5.  3.  1.6 0.2]\n",
      " [5.  3.4 1.6 0.4]\n",
      " [5.2 3.5 1.5 0.2]\n",
      " [5.2 3.4 1.4 0.2]\n",
      " [4.7 3.2 1.6 0.2]\n",
      " [4.8 3.1 1.6 0.2]\n",
      " [5.4 3.4 1.5 0.4]\n",
      " [5.2 4.1 1.5 0.1]\n",
      " [5.5 4.2 1.4 0.2]\n",
      " [4.9 3.1 1.5 0.2]\n",
      " [5.  3.2 1.2 0.2]\n",
      " [5.5 3.5 1.3 0.2]\n",
      " [4.9 3.6 1.4 0.1]\n",
      " [4.4 3.  1.3 0.2]\n",
      " [5.1 3.4 1.5 0.2]\n",
      " [5.  3.5 1.3 0.3]\n",
      " [4.5 2.3 1.3 0.3]\n",
      " [4.4 3.2 1.3 0.2]\n",
      " [5.  3.5 1.6 0.6]\n",
      " [5.1 3.8 1.9 0.4]\n",
      " [4.8 3.  1.4 0.3]\n",
      " [5.1 3.8 1.6 0.2]\n",
      " [4.6 3.2 1.4 0.2]\n",
      " [5.3 3.7 1.5 0.2]\n",
      " [5.  3.3 1.4 0.2]\n",
      " [7.  3.2 4.7 1.4]\n",
      " [6.4 3.2 4.5 1.5]\n",
      " [6.9 3.1 4.9 1.5]\n",
      " [5.5 2.3 4.  1.3]\n",
      " [6.5 2.8 4.6 1.5]\n",
      " [5.7 2.8 4.5 1.3]\n",
      " [6.3 3.3 4.7 1.6]\n",
      " [4.9 2.4 3.3 1. ]\n",
      " [6.6 2.9 4.6 1.3]\n",
      " [5.2 2.7 3.9 1.4]\n",
      " [5.  2.  3.5 1. ]\n",
      " [5.9 3.  4.2 1.5]\n",
      " [6.  2.2 4.  1. ]\n",
      " [6.1 2.9 4.7 1.4]\n",
      " [5.6 2.9 3.6 1.3]\n",
      " [6.7 3.1 4.4 1.4]\n",
      " [5.6 3.  4.5 1.5]\n",
      " [5.8 2.7 4.1 1. ]\n",
      " [6.2 2.2 4.5 1.5]\n",
      " [5.6 2.5 3.9 1.1]\n",
      " [5.9 3.2 4.8 1.8]\n",
      " [6.1 2.8 4.  1.3]\n",
      " [6.3 2.5 4.9 1.5]\n",
      " [6.1 2.8 4.7 1.2]\n",
      " [6.4 2.9 4.3 1.3]\n",
      " [6.6 3.  4.4 1.4]\n",
      " [6.8 2.8 4.8 1.4]\n",
      " [6.7 3.  5.  1.7]\n",
      " [6.  2.9 4.5 1.5]\n",
      " [5.7 2.6 3.5 1. ]\n",
      " [5.5 2.4 3.8 1.1]\n",
      " [5.5 2.4 3.7 1. ]\n",
      " [5.8 2.7 3.9 1.2]\n",
      " [6.  2.7 5.1 1.6]\n",
      " [5.4 3.  4.5 1.5]\n",
      " [6.  3.4 4.5 1.6]\n",
      " [6.7 3.1 4.7 1.5]\n",
      " [6.3 2.3 4.4 1.3]\n",
      " [5.6 3.  4.1 1.3]\n",
      " [5.5 2.5 4.  1.3]\n",
      " [5.5 2.6 4.4 1.2]\n",
      " [6.1 3.  4.6 1.4]\n",
      " [5.8 2.6 4.  1.2]\n",
      " [5.  2.3 3.3 1. ]\n",
      " [5.6 2.7 4.2 1.3]\n",
      " [5.7 3.  4.2 1.2]\n",
      " [5.7 2.9 4.2 1.3]\n",
      " [6.2 2.9 4.3 1.3]\n",
      " [5.1 2.5 3.  1.1]\n",
      " [5.7 2.8 4.1 1.3]\n",
      " [6.3 3.3 6.  2.5]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.1 3.  5.9 2.1]\n",
      " [6.3 2.9 5.6 1.8]\n",
      " [6.5 3.  5.8 2.2]\n",
      " [7.6 3.  6.6 2.1]\n",
      " [4.9 2.5 4.5 1.7]\n",
      " [7.3 2.9 6.3 1.8]\n",
      " [6.7 2.5 5.8 1.8]\n",
      " [7.2 3.6 6.1 2.5]\n",
      " [6.5 3.2 5.1 2. ]\n",
      " [6.4 2.7 5.3 1.9]\n",
      " [6.8 3.  5.5 2.1]\n",
      " [5.7 2.5 5.  2. ]\n",
      " [5.8 2.8 5.1 2.4]\n",
      " [6.4 3.2 5.3 2.3]\n",
      " [6.5 3.  5.5 1.8]\n",
      " [7.7 3.8 6.7 2.2]\n",
      " [7.7 2.6 6.9 2.3]\n",
      " [6.  2.2 5.  1.5]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [5.6 2.8 4.9 2. ]\n",
      " [7.7 2.8 6.7 2. ]\n",
      " [6.3 2.7 4.9 1.8]\n",
      " [6.7 3.3 5.7 2.1]\n",
      " [7.2 3.2 6.  1.8]\n",
      " [6.2 2.8 4.8 1.8]\n",
      " [6.1 3.  4.9 1.8]\n",
      " [6.4 2.8 5.6 2.1]\n",
      " [7.2 3.  5.8 1.6]\n",
      " [7.4 2.8 6.1 1.9]\n",
      " [7.9 3.8 6.4 2. ]\n",
      " [6.4 2.8 5.6 2.2]\n",
      " [6.3 2.8 5.1 1.5]\n",
      " [6.1 2.6 5.6 1.4]\n",
      " [7.7 3.  6.1 2.3]\n",
      " [6.3 3.4 5.6 2.4]\n",
      " [6.4 3.1 5.5 1.8]\n",
      " [6.  3.  4.8 1.8]\n",
      " [6.9 3.1 5.4 2.1]\n",
      " [6.7 3.1 5.6 2.4]\n",
      " [6.9 3.1 5.1 2.3]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [6.8 3.2 5.9 2.3]\n",
      " [6.7 3.3 5.7 2.5]\n",
      " [6.7 3.  5.2 2.3]\n",
      " [6.3 2.5 5.  1.9]\n",
      " [6.5 3.  5.2 2. ]\n",
      " [6.2 3.4 5.4 2.3]\n",
      " [5.9 3.  5.1 1.8]]\n",
      "\n",
      " target의 type은 : <class 'numpy.ndarray'>\n",
      "target의 shape : 150\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# load_irs() 가 반환하는 객체의 키인  'feature_names','target_names','data', 'target' 이 가리키는 값을 출력\n",
    "print('\\n feature_names의 type:',type(iris_data.feature_names)) #리스트 타입\n",
    "print(' feature_names의 shape:',len(iris_data.feature_names))\n",
    "print(iris_data.feature_names)\n",
    "\n",
    "print('\\n target_names의 tpye:',type(iris_data.target_names)) #넘파이 어레이 타입\n",
    "print( 'target_names의 shape:',len(iris_data.target_names))\n",
    "print(iris_data.target_names)\n",
    "\n",
    "print('\\n data의 type은 : ',type(iris_data.data)) #넘파이 어레이 타입\n",
    "print( 'data의 shape : ',len(iris_data.data))\n",
    "print(iris_data.data)\n",
    "\n",
    "print('\\n target의 type은 :',type(iris_data.target)) #넘파이 어레이 타이뷰\n",
    "print( 'target의 shape :',len(iris_data.target))\n",
    "print(iris_data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e0071",
   "metadata": {},
   "source": [
    "# 학습 / 테스트 데이터 세트 분리 -train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bda56b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 :  1.0\n"
     ]
    }
   ],
   "source": [
    "# 붓꽃\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "train_data = iris.data\n",
    "train_label= iris.target\n",
    "dt_clf.fit(train_data,train_label)\n",
    "\n",
    "#  학습 데이터 세트로 예측 수행\n",
    "pred = dt_clf.predict(train_data)\n",
    "print(\"예측 정확도 : \",accuracy_score(train_label,pred)) # 100프로가 절대 나올수가 없음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00fe496f",
   "metadata": {},
   "source": [
    "# 분리\n",
    "test_size : 테스트 데이터 세트 크기 설정 /디폴트 0.25 <br>\n",
    "train_size : 학습용 데이터 세트 크기 설정 /(test_size를 통상적으로 사용해서 잘 안씀)<br>\n",
    "shuffle : 데이터 분리전 데이터를 섞을지 설정 /디폴트 True<br>\n",
    "randomstate : 동일한 학습/테스트용 데이터 세트를 생성하기 위해 주어지는 난수 값 train_test_split는 호출시 무작위로 데이터분리함\n",
    "\n",
    "train_test_split() 의 반환값은 튜플 형태 \n",
    "1. 순차적으로  학습용 데이터의 피처데이터\n",
    "2. 테스트용 데이터의 피처 데이터셋 \n",
    "3. 학습용 데이터의 레이블 데이터셋\n",
    "4. 테스트용 데이터의 레이블 데이터 세트가 반환된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b800c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 붓꽃\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "iris_data = load_iris()\n",
    "# 전체의 30% 테스트 데이터 70%를 학습용 데이터 \n",
    "X_train,X_test,y_train,y_test = train_test_split(iris_data.data , iris_data.target,\n",
    "                                                test_size = 0.3 ,random_state=121)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "60f3a040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "예측 정확도 : 0.9556\n"
     ]
    }
   ],
   "source": [
    "# DecisionTreeClassifier를 학습하고 예측정확도 측정\n",
    "dt_clf.fit(X_train,y_train)\n",
    "pred = dt_clf.predict(X_test)\n",
    "\n",
    "print(\"예측 정확도 : {0:.4f}\".format(accuracy_score(y_test,pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904cf2c2",
   "metadata": {},
   "source": [
    "# 교차 검증 \n",
    "과적합 등 성능저하의 우려가 있기 때문에 교차검증이 필요하다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b32049",
   "metadata": {},
   "source": [
    "-폴드 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0a966717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "붓꽃 데이터 세트 크기 : 150\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris # iris 데이터 호출\n",
    "from sklearn.tree import DecisionTreeClassifier # 클러스터를 위한 패키지\n",
    "from sklearn.metrics import accuracy_score  # 정확도 판별을 위한 패키지\n",
    "from sklearn.model_selection import KFold # KFold 교차검증을 위한 패키지\n",
    "import numpy as np\n",
    "\n",
    "iris = load_iris() # 변수명 지정\n",
    "features = iris.data\n",
    "label = iris.target\n",
    "dt_clf = DecisionTreeClassifier(random_state =156) # 동일한 값을 받기위한 난수값 지정\n",
    "\n",
    "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성\n",
    "kfold = KFold(n_splits = 5) # kfold 객체 5개 생성\n",
    "cv_accuracy= []\n",
    "\n",
    "print('붓꽃 데이터 세트 크기 :',features.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d7ccc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1 교차 검증 정확도 : 1.0, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "\n",
      "1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "##평균 정확도 :  0.9090909090909091\n",
      "\n",
      "2 교차 검증 정확도 : 0.9667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "\n",
      "2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
      " 54 55 56 57 58 59]\n",
      "\n",
      "##평균 정확도 :  0.9138916666666667\n",
      "\n",
      "3 교차 검증 정확도 : 0.8667, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "\n",
      "3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
      " 84 85 86 87 88 89]\n",
      "\n",
      "##평균 정확도 :  0.9102615384615385\n",
      "\n",
      "4 교차 검증 정확도 : 0.9333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "\n",
      "4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
      "\n",
      "##평균 정확도 :  0.9119071428571429\n",
      "\n",
      "5 교차 검증 정확도 : 0.7333, 학습 데이터 크기 : 120, 검증 데이터 크기 : 30\n",
      "\n",
      "5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
      " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
      "\n",
      "##평균 정확도 :  0.9\n"
     ]
    }
   ],
   "source": [
    "# KFold 객체의 split를 호출해 교차 검증 수행시마다 학습과 검증을 반복해 예측 정확도를 측정\n",
    "\n",
    "n_iter = 0\n",
    "\n",
    "# KFold 객체의 split()를 호출하면 폴드 별 학습용 , 검증용 테스트의 로우 인덱스를 array롤 반환\n",
    "\n",
    "for train_index,test_index in kfold.split(features):\n",
    "    # kfold.split()로 반환된 인덱스를 이용해 학습용 , 검증용 테스트 데이터 추출\n",
    "    X_train,X_test = features[train_index],features[test_index]\n",
    "    y_train,y_test = label[train_index],label[test_index]\n",
    "    \n",
    "    # 학습 및 예측\n",
    "    dt_clf.fit(X_train,y_train)\n",
    "    pred = dt_clf.predict(X_test)\n",
    "    n_iter +=1\n",
    "    \n",
    "    # 반복시마다 정확도 측정\n",
    "    accuracy = np.round(accuracy_score(y_test,pred),4)\n",
    "    train_size = X_train.shape[0] # 결과값 (120,4) 의 첫번째 120\n",
    "    test_size = X_test.shape[0] # 결과값 (30,4) 의 첫번째 30\n",
    "    print('\\n{0} 교차 검증 정확도 : {1}, 학습 데이터 크기 : {2}, 검증 데이터 크기 : {3}'.format(n_iter , accuracy,train_size,test_size))\n",
    "    print('\\n{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
    "    cv_accuracy.append(accuracy)\n",
    "          \n",
    "# 개별 iteration 별 정확도를 합하여 평균 정확도 계산\n",
    "    print('\\n##평균 정확도 : ',np.mean(cv_accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a0c789",
   "metadata": {},
   "source": [
    "# Stratified K폴드\n",
    "불균형한 분포도를 가진 레이블 데이터 집합을 위한 K폴드 방식<br>\n",
    "즉 특정 레이블 ㅂ값이 특이하게 많거나 매우적어서 값의 분포가 한쪽으로 치우치는 것을 말한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05ebde49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas as pd\n",
    "\n",
    "iris = load_iris()\n",
    "iris_df = pd.DataFrame(data = iris.data , columns = iris.feature_names)\n",
    "iris_df['label'] = iris.target\n",
    "iris_df['label'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a8df767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증 : 1\n",
      "학습 레이블 데이터분포 :\n",
      " 0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      " 검증 레이블 데이터 분포:\n",
      " 0    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 2\n",
      "학습 레이블 데이터분포 :\n",
      " 0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      " 검증 레이블 데이터 분포:\n",
      " 1    50\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증 : 3\n",
      "학습 레이블 데이터분포 :\n",
      " 0    50\n",
      "1    50\n",
      "2    20\n",
      "Name: label, dtype: int64\n",
      " 검증 레이블 데이터 분포:\n",
      " 2    50\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 학습 / 검증 레이블 데이터 값의 분포도 확인\n",
    "kfold = KFold(n_splits=3)\n",
    "n_iter= 0\n",
    "for trian_index , test_index in kfold.split(iris_df):\n",
    "    n_iter +=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test =  iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증 : {0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터분포 :\\n',label_train.value_counts())\n",
    "    print(' 검증 레이블 데이터 분포:\\n',label_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c8e05962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 교차 검증:1\n",
      "학습 레이블 데이터 분포 : \n",
      " 2    34\n",
      "0    33\n",
      "1    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      "  0    17\n",
      "1    17\n",
      "2    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증:2\n",
      "학습 레이블 데이터 분포 : \n",
      " 1    34\n",
      "0    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      "  0    17\n",
      "2    17\n",
      "1    16\n",
      "Name: label, dtype: int64\n",
      "## 교차 검증:3\n",
      "학습 레이블 데이터 분포 : \n",
      " 0    34\n",
      "1    33\n",
      "2    33\n",
      "Name: label, dtype: int64\n",
      "검증 레이블 데이터 분포:\n",
      "  1    17\n",
      "2    17\n",
      "0    16\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3)\n",
    "n_iter = 0\n",
    "\n",
    "for train_index ,test_index in skf.split(iris_df ,iris_df['label']):\n",
    "    n_iter +=1\n",
    "    label_train = iris_df['label'].iloc[train_index]\n",
    "    label_test = iris_df['label'].iloc[test_index]\n",
    "    print('## 교차 검증:{0}'.format(n_iter))\n",
    "    print('학습 레이블 데이터 분포 : \\n',label_train.value_counts())\n",
    "    print('검증 레이블 데이터 분포:\\n ',label_test.value_counts())\n",
    "\n",
    "    \n",
    "# 0 , 1, 2 값이 각가 33개로 레이블 별로 동일하게 할당\n",
    "# 검증 레이블 역시 17개로 동일하게 할당\n",
    "# 이렇게 분할되어야 레이블 값 0,1,2 를 모두 학습할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
